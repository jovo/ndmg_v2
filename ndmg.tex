\documentclass[11pt]{article}
\input{preamble.tex}
\usepackage{enumitem}

\title{
A Low-Resource Pipeline to Democratize Multi-Modal Connectome Estimation and Analysis
% A High-Throughput Pipeline Identifies Robust Connectomes But Troublesome Variability
}


\begin{document}

\maketitle
\noindent\parbox{0.9\textwidth}{
\normalsize\color{lgray} Gregory~Kiar$^*$, Eric~W.~Bridgeford$^*$,  William~R.~Gray~Roncal$^*$, 
Consortium for Reliability and Reproducibility (CoRR), 
Vikram~Chandrashekhar, Disa~Mhembere,  Sephira~Ryman,  Xi-Nian~Zuo,  Daniel S.~Margulies, R. Cameron Craddock, Carey E.~Priebe,
Rex~Jung, Vince~D.~Calhoun, 
Brian Caffo, Randal~Burns, Michael P.~Milham,  
Joshua~T.~Vogelstein$^\dagger$
\\%$^1$
%Johns Hopkins University, University of New Mexico, %$^2$
%Child Mind Institute, \& University of Chinese Academy of Sciences
%,\& Research Center for Lifespan Development of Mind and Brain (CLIMB), Institute of Psychology, Chinese Academy of Sciences
}
\thispagestyle{empty}
\medskip
\vspace{10pt}


\noindent
\textbf{Modern scientific discovery depends on collecting large heterogeneous datasets with many sources of variability, and applying domain-specific pipelines from which one can draw  insight or clinical utility. For example, macroscale connectomics studies require complex pipelines to process raw functional or diffusion data and estimate connectomes. Individual studies tend to customize pipelines to their needs, raising concerns about their reproducibility,  and adding to a longer list of factors that may differ across studies (including sampling, experimental design, and data acquisition protocols), resulting in failures to replicate. Mitigating these issues requires multi-study datasets and the development of pipelines that can be applied across them. We developed NeuroData's MRI to Graphs (\ndmg) pipeline using several functional and diffusion studies, including the Consortium for Reliability and Reproducibility, to estimate connectomes. Without any manual intervention or parameter tuning, \ndmg~ran on 25 different studies ($\approx$ 6,000 scans) from 15 sites,  with each scan resulting in a biologically plausible connectome (as assessed by multiple quality assurance metrics at each processing stage). For each study, the connectomes from \ndmg~are more similar within than across individuals, indicating that \ndmg~is preserving biological variability. Moreover, the connectomes exhibit near perfect consistency for certain connectional properties across every scan, individual, study, site, and modality; these include stronger ipsilateral than contralateral connections and stronger homotopic than heterotopic connections. 
% @JV: review says:  it is unclear what the sentence refers to
Yet, the magnitude of the differences varied across individuals and studies---much more so when pooling data across sites, even after controlling for study, site, and basic demographic variables (i.e., age, sex, and ethnicity). This indicates that other experimental variables (possibly those not measured or reported) are contributing to this variability, which if not accounted for can limit the value of aggregate datasets, as well as expectations regarding the accuracy of findings and likelihood of replication. We, therefore, provide a set of principles to guide the development of pipelines capable of pooling data across studies while maintaining biological variability and minimizing measurement error. This open science approach provides us with an opportunity to understand and eventually mitigate spurious results for both past and future studies.
}
%Modern scientific discovery depends on collecting large heterogeneous datasets with many sources of variability, and applying domain-specific pipelines from which one can draw  insight or clinical utility. For example, macroscale connectomics studies require complex pipelines to process raw functional or diffusion data and estimate connectomes. Individual studies tend to customize pipelines to their needs, raising concerns about their reproducibility,  and adding to a longer list of factors that may differ across studies (including sampling, experimental design, and data acquisition protocols), resulting in failures to replicate. Mitigating these issues requires multi-study datasets and the development of pipelines that can be applied across them. We developed NeuroData's MRI to Graphs (NDMG) pipeline using several functional and diffusion studies, including the Consortium for Reliability and Reproducibility, to estimate connectomes. Without any manual intervention or parameter tuning, NDMG ran on 25 different studies (~6,000 scans) from 15 sites,  with each scan resulting in a biologically plausible connectome (as assessed by multiple quality assurance metrics at each processing stage). For each study, the connectomes from NDMG are more similar within than across individuals, indicating that NDMG is preserving biological variability. Moreover, the connectomes exhibit near perfect consistency for certain connectional properties across every scan, individual, study, site, and modality; these include stronger ipsilateral than contralateral connections and stronger homotopic than heterotopic connections. Yet, the magnitude of the differences varied across individuals and studies - much more so when pooling data across sites, even after controlling for study, site, and basic demographic variables (i.e., age, sex, and ethnicity). This indicates that other experimental variables (possibly those not measured or reported) are contributing to this variability, which if not accounted for can limit the value of aggregate datasets, as well as expectations regarding the accuracy of findings and likelihood of replication. We, therefore, provide a set of principles to guide the development of pipelines capable of pooling data across studies while maintaining biological variability and minimizing measurement error. This open science approach provides us with an opportunity to understand and eventually mitigate spurious results for both past and future studies.

% \begin{multicols}{2}


% @AK: "if you mean failures in surface reconstruction by FreeSurfer, I didn't mention in the Mindboggle article that 1/3 of our EMBARC subjects' surface reconstructions were deemed unfit for further analysis, but:
% http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005350
% Figure 2 shows gyral crown clipping.
% And: " For 16 cortical regions in the 40 subjects, we measured scan-rescan reliability of cortical thickness measures, and we compared thickness measures with published estimates based on manual delineations of MR images of living brains [115]. Forty percent of FreeSurfer estimates for the 640 labels were in the published ranges of values ...  (as mentioned above, Klauschen observed that FreeSurfer underestimates gray matter and overestimates white matter [78]). " 

% @GK: we can fix how we do tensor estimation and stuff in native space with this: https://www.mitpressjournals.org/doi/abs/10.1162/NETN_a_00035


\section{Introduction}
% 
% Action: 
% 1. establish principles for pipelines
% 2. open source data including those with multiple measurements
% 3. open source pipeline adhering to principles applied to those data 
% 
% Reproducibility and replicability are fundamental to scientific progress.  
% When studies  replicate using new data or methods, the validity and utility  of inferences in both studies are strengthened.  
% Yet, many studies fail to replicate across disciplines~\cite{Ioannidis2005}, including numerous examples in neuroimaging~\cite{Button2013}. 
% 
%  Failures to replicate can have many causes, including variability in sampling, recruitment, experimental design, data acquisition details (e.g., phenotyping instruments, scanners, scan protocol parameters), quality control, data processing, data analysis, or statistical testing~\cite{Bennett2011-aw}, as well as unintended/ unknown sources of measurement error, underpowered samples, bad luck or poor research conduct practices~\cite{John2012, Loken2017}.
% The degree to which each of these factors cause problems impacts the efficacy of strategies to mitigate these problems in future studies.  There is therefore a need to develop computational and statistical pipelines that enable evaluating the impact of each of these potential factors. 
% 



Recent developments in technology enable experimentalists to collect increasingly large, complex, and heterogeneous data. 
Any single study can include both raw multi-modal data and
extensive metadata, 
including sample design, experimental protocols,  data acquisition, and subject specific demographics/phenotypics. Each of these variables adds different sources of variability, which can hamper our ability to interpret and/or generalize results~\cite{Kelly2012, Kaiser}.  Moreover, often only a subset of the potential sources of variability are documented or reported~\cite{Yan2013-vy}.  
Interpreting these data therefore requires deep data processing pipelines. Such pipelines are particularly important when attempting to enlarge sample size and increase power by aggregating data across multiple studies. These pipelines, however, can introduce additional sources of variability, if different pipelines are used on different datasets, or the same pipeline is applied across datasets but requires substantial tuning or manual intervention, or is run using different operating systems~\cite{Gronenschild2012-of}.
These sources of variability can collectively swamp the signal of interest, yielding studies with questionable reproducibility, scientific validity, and/or clinical utility. 

Studies in neuroimaging exemplify these properties. The data from a single study consist of structural, functional, and/or diffusion magnetic resonance imaging (sMRI, fMRI, and dMRI) scans, from multiple individuals. The metadata associated with a study includes the time, date, and location of the scans, the make and model of the scanner hardware and software, scanner acquisition protocols, as well as the demographic information from each individual, only some of which may be recorded and reported. A number of investigators have developed  processing pipelines for one or more of these modalities~\cite{cpac, Cui2013, Daducci2012, mrcap, migraine, Song2011, Yan2010, Yan2016, Wang2015, Calhoun2001-wc, Xu2015,Zuo2013}, but none of the pipelines are designed to address the  variability alluded to above, or work across both fMRI and dMRI.  


For example, a number of studies have identified frequently uncontrolled  variables that can radically alter the results of downstream inferences, such as menstrual cycle status~\cite{Yan2013-vy}.
Others have demonstrated that some statistics and normalization procedures result in stable parameter estimates across fMRI measurements \emph{within} an individual and study, but those analyses lacked a coherent statistical model, did not compare across studies, and did not consider dMRI data~\cite{Yan2013-vy}. 
A few investigations have pooled data across studies, with mixed results. With enough samples, certain properties are apparently preserved~\cite{Thompson2016-by,Abrol2017-fk}. Alternately, the use of sophisticated machine learning techniques can mitigate some of these issues~\cite{varoquaux2013learning}. Nonetheless, many studies continue to fail to be replicated~\cite{Button2013}. 





To rigorously identify and quantify the sources of variability both within and across  multi-modal neuroimaging  requires (1) data and (2) a pipeline. The requisite data includes  numerous datasets with multiple measurements per individual---including data that both conserve and vary a number of different factors. The requisite pipeline must be able to fully  process each sample and study, and analyze the results both within and across studies using a coherent statistical model.  


The Consortium of Reliability and Reproducibility (CoRR) consists of about 30 different studies from nearly 20 different institutions around the world that provide the necessary data~\cite{corr}. But no existing pipeline can successfully estimate and meaningfully process every scan in this dataset---including both functional and diffusion data---while also quantifying the magnitude and source of variability amongst them. 
We, therefore, established several principles and metrics to guide the development of pipelines.  
We developed an approach, ``Neuro Data MRI to Graphs'' (\ndmg), that 
meets or exceeds standards along each of the above mentioned principles. We validated our pipeline by running \ndmg~on 11 dMRI  studies comprising 3,227 individuals with 4,347 scans, 
and 18 fMRI  studies comprising 714 individuals with 1,646 scans. 
For each scan \ndmg~estimates  a ``connectome'' (a functional or structural map of connectivity) at 24 different spatial resolutions---yielding a total of  $>100,000$ estimated connectomes---all of which are publicly available from \url{http://m2g.io}. This is the largest open database of connectomes~\cite{brown2016connected},
and one of the largest mega-analyses (inference across studies) of multi-modal connectomics data to date~\cite{varoquaux2013learning, vidaurre2017discovering}. 



These connectomes provided the data that led us to develop statistical connectomics methods to quantify various connectome properties, such as the relative probability of ipsilateral vs.~contralateral connections and homotopic vs.~heterotopic connections. While these properties have been previously noted in single studies~\cite{Stark2008,Zuo2010,Gee2011}, this work demonstrates that aspects of these properties are preserved both across individuals and studies upon optimizing and harmonizing the pipeline. Nonetheless, within session, site, study, and demographic cohorts, substantial variability remained in the \emph{magnitude} of these properties. 
Moreover, we observed a considerably higher degree of variability across sites, studies, and demographic cohorts. In part, this variability may be due to legitimate biological heterogeneity that could not be accounted for using the limited phenotyping available. However, a substantial portion of that variability is likely reflective of experimental and/or measurement error.
This variability can partially explain recent failures of replicability in neuroimaging~\cite{Button2013}, as well as the lack of clinically useful neuroimaging based biomarkers~\cite{APA12}. This work therefore motivates significant further efforts in measurement and/or analysis to mitigate ``batch effects’’ in neuroimaging. 
Other disciplines with similar findings have resolved these issues by revolutionizing their measurement strategy (for example, genomics moved away from microarrays because sequencing can be significantly more reliable than microarray measurements~\cite{SEQCMAQC-III_Consortium2014-ij})---though only after all efforts to remediate existing methods failed. For imaging, more comprehensively phenotyped individuals, and more coordinated data acquisition protocols, can be a first step towards studies generating sufficiently accurate and reliable inferences and clinical biomarkers.

%%%%%%%%
% \input{table_pipelines.tex}
%%%%%%%%



\section{Results}


% \subsection{Individual-Level Analysis}

%%%%%%%
\input{figure_ndmgpipeline.tex}
%%%%%%%
\clearpage
%%%%%%%
%\input{figure_ohbm_discr.tex}
%%%%%%%

\subsection{Individual-Level Analysis}

In the individual-level analysis, each individual  undergoes some number of sessions, during which multiple different modalities can be collected.
The input to \ndmg~for a given individual is  the collection of scans and some metadata for each scan, including a structural scan, % (T1w/MPRAGE), 
and either, or both of, (1) a diffusion scan, including the diffusion parameters files,  and (2) a functional scan, including the slice acquisition sequence.
The individual-level of \ndmg~analysis leverages existing open source tools, including
the fMRI Software Library (FSL) ~\cite{fsl1, fsl2, fsl3}, Dipy~\cite{dipy}, the MNI152 atlas~\cite{mni152}, and a variety of parcellations defined in the MNI152 space~\cite{desikan, aal, jhu, harvardoxford, talairach, slab907, slab1068, pvt, glasser} (see \ref{app:parcels} for details about built-in parcellations included). 
% @reb: vince says: [hey, we have a number of ICA parcellation schemes, the way we like to use them is to run spatially constrained ICA on new data using these as priors...if you want to do something with this let me know, possible collaboration going forward? ;-) ] let's get them in our set?
All algorithms requiring hyper-parameter selection were initially set to the suggested parameters for each tool, and tuned to improve the accuracy, reliability, expediency, and robustness of the results.
The output of each processing stage includes data derivatives and QA figures to enable individualized accuracy assessments.
The QA figures at many stages include cross-sectional images at different depths in the three canonical planes (sagittal, coronal, and axial) of images or overlays. Example QA figures are provided in \ref{app:dpipe} and \ref{app:fpipe}.
%---which we refer to as QAX---as specified below.
%A crucial component of the design of \ndmg~was to include  quality assurance (QA) figures for each stage to the pipeline, to enable users to easily detect whether or not the pipeline is producing accurate results. 
%Snapshots of these QA figures are shown Figure~\ref{fig:ndmgpipeline}.%, whereas exemplars are provided in \ref{app:pipeline}.

% \paragraph{Individual-Level Diffusion Analysis}

The \ndmgd~pipeline consists of four key components: (1) registration, (2) tensor estimation, (3) tractography, and (4) graph generation (see Figure~\ref{fig:ndmgpipeline} for an illustration, and 
\ref{app:dpipe} for further details). It was optimized on the Kirby21 dataset, and then applied to the remaning 10 datasets.
Individual-level analysis in \ndmgd~takes approximately $1.5$ hours to complete using 1~CPU core and 12~GB of RAM at 1 mm$^3$ resolution.
The individual-level analysis was run on 11 studies, including 3,227 individuals and 4,347 scans. Each dataset generated connectomes across each of the parcellations in \ref{app:parcels}, resulting in 104,328 functional brain-graphs.

The \ndmgf~pipeline can be broken up into four key components: (1) preprocessing, (2) registration, (3) nuisance correction, and (4) graph generation (see Figure~\ref{fig:ndmgpipeline} for an illustration and  \ref{app:fpipe} for further details).
The \ndmgf~pipeline was constructed starting with the optimal processing pipeline identified in Wang et. al~\cite{discriminability} using CPAC~\cite{cpac}. Hyperparameters and further algorithm selection was optimized for reliability based on multiple measurement studies (including test-retest).
Individual-level analysis in \ndmgf~takes approximately 20~minutes to complete using 1~CPU core and 3~GB of RAM at 2 mm$^3$resolution.
The individual-level analysis was run on 714 individuals with 1,646 scans from 18 studies, generating connectomes across each of the 24 parcellations in \ndmgd, and resulting in 39,504 total brain-graphs.

% \paragraph{Multi-Scale Multi-Connectome Analysis}

% For both diffusion and functional MRI, \ndmg~downsamples the voxel-wise graphs to obtain weighted graphs for many different parcellation schemes. This includes: (1) neuroanatomically delineated parcellations, such as the HarvardOxford cortical and sub-cortical atlases~\cite{harvardoxford}, the JHU~\cite{jhu}, Talairach~\cite{talairach}, Desikan~\cite{desikan}, and AAL~\cite{aal} atlases; (2) algorithmically delineated parcellations, such as Slab907~\cite{slab907}, Slab1068~\cite{slab1068}, and CC200~\cite{cpac};  and (3) 16 down-sampled parcellations ranging from 70 to 72,783 nodes~\cite{glocal}.  
% For each, the \emph{multi-connectome} is defined by the set of nodes from a particular parcellation, and the set of (potentially weighted and/or directed) edges from each modality.

For both diffusion and functional MRI, the QA for graph generation includes a heat map of the adjacency matrix, the number of non-zero edges, and several multivariate graph statistics (one statistic per vertex in the graph) including:  betweenness centrality, clustering coefficient, hemisphere-separated degree sequence, edge weight, eigenvalues of the graph laplacian, and locality statistic-1~\cite{glocal}.
We developed the hemisphere-separated degree sequence to indicate the ipsilateral and contralateral degree for each vertex, which we found quite useful for QA.  
\ref{app:graphgenf} includes definitions and implementation details for each of the statistics.
Supplementary Figure ~\ref{fig:multiscale} shows, for a single individual, the graph summary statistics for the multi-connectome (including both functional and diffusion) across the set of atlases described above.
% @reb: post submission, consider overlaying the D & F plots 

%%%%%%%
\input{table_discr.tex}
%%%%%%%

\subsection{Group-Level Analysis}

We ran \ndmg~on the 11 diffusion and 18 functional studies listed in 
Table~\ref{tab:data}.
For each, \ndmg~group-level analysis computes and plots group-level graph summary and reliability statistics. 

%%%%%%%
\input{figure_graphqa.tex}
%%%%%%%

% \paragraph{Group Level Implementation Strategy}

Leveraging previous efforts developed in our  ``Science in the Cloud''~\cite{sic} manuscript, multiple scans and studies are evaluated in parallel for participant-level analysis, and the derivatives are pooled for group-level analysis, much like typical map-reduce approaches (consistent with the BIDS app specification~\cite{bidsapps}). The parallel  implementation uses the Amazon Web Services (AWS) cloud, in particular leveraging their storage (S3) and high performance computing (Batch) services. Data are stored in an S3 bucket enabling  the \ndmg~cloud-API connectome estimation pipeline to process all scans on Amazon Batch in parallel. In practice,  AWS limits the number of parallel threads users are allowed to launch (to prevent accidental spending). After connectome estimation is complete, the same cloud-API exposed by \ndmg~enables group-level analysis to be launched and parallelized across each parcellation for all scans within each study. We were able to compute diffusion connectomes at 24~scales for each of the publicly available 2,861~scans (totaling 68,664~connectomes) in under one day and \$1,000. Had we processed each scan in parallel, cost would have remained the same but only taken $1.5$~hours.

% \paragraph{Group-Level Graph Summary Statistics}

Each scan's estimated connectome can be summarized by a set of graph statistics, as described above. For group-level analysis, we visualize each scan's summary statistics overlaid on one another. For example, Figure~\ref{fig:graphqa} demonstrates that each diffusion graph from the BNU3 dataset using the Desikan atlas has relatively similar values for the statistics (we use the Desikan atlas for the remainder of the analyses unless otherwise specified). Moreover, it is clear from both the degree plot and the mean connectome plot that the dMRI connectomes from this study tend to have more connections within a hemisphere than across a hemisphere, as expected. For the fMRI connectomes, however, the homotopic connections---that is, connections from one region on a hemisphere to the same region on the other hemisphere---seem particularly strong.
%Supplementary Figure ~\ref{fig:graphqaf} shows example group-level analysis for the same study's functional data.
 
%\ref{app:multi} illustrates how \ndmg~also computes the average value for each univariate and multivariate statistic for each atlas, and demonstrates similarities across scales, indicating that that the basic structure of the connectomes is preserved across different atlases.


%\subsubsection{\ndmgf~Individual-Level Pipeline}

\paragraph{Group-Level Discriminability}
\label{sec:disc}

Group-level results from \ndmg~that include repeated measurements are quantitatively assessed using a statistic called discriminability~\cite{discriminability}.
The group's sample discriminability estimates the probability that two observations within the same class are more similar to one another than to objects belonging to a different class:
\begin{equation}
D = Pr(|| a_{ij} - a_{ij'} || \leq || a_{ij} - a_{i'j'} ||).
\label{eq:disc}
\end{equation}
In the context of reliability in \ndmg, each connectome, $a_{ij}$, is compared to other connectomes belonging to the same individual, $a_{ij'}$, and to all connectomes belonging to other individuals, $a_{i'j'}$.
A perfect discriminability score indicates that for all observations within the group, each connectome is more like connectomes from the same individual than others.
Table~\ref{tab:data} lists the discriminability score of each study with repeated measurements (five dMRI studies and sixteen fMRI).
 \ndmgd~achieves a discriminability score of nearly 0.99 or greater on most studies (the lowest score was nearly 0.9).  \ndmgf~achieves a discriminability score around 0.9 on all studies. 
These high discriminability scores  were achieved by optimizing both \ndmgd~and \ndmgf~on a subset of the data.  Specifically, \ndmgd~was optimized using only the Kirby21 study, to achieve a perfect discriminability score.  Nonetheless, the other studies achieved comparably high discriminability scores, despite the fact that the Kirby21 used a Philips scanner, unlike any of the other studies. Moreover, Kirby21's age distribution is substantially different from several of the other dMRI studies (see Table~\ref{tab:data}).  
Similarly, \ndmgf~was optimized using only 13 of the 18 studies, and yet discriminability on the remaining studies remained equally high~\cite{discriminability}, even though they also exhibited large study demographic and acquisition protocol variability.
Finally, \ndmg~was not optimized explicitly at all on multimodal data, nonetheless, for all datasets with multiple scans per subject with both dMRI and fMRI, using the multimodal connectomes improved (or did not decrease) discriminability relative to either modality on its own.
That \ndmg's discriminability score is robust to data acquisition details and study demographics across modalities suggests that scientific results may also be robust to such sources of variability.

% Note that we invested significant effort in both pipelines to achieve these high discriminability scores, and to our knowledge, no other pipelines have been assessed with regards to discriminability. 
 
 % or any other reliability metric.
%
%The discriminability score obtained if a pipeline produced random outputs is summarized in Equation~\ref{eq:chance}, and is a function of the number of classes, $k$, the number of elements in each class, $M_i$, and the total number of observations, $N$:
%
%\begin{equation}
%C = \frac{\sum_{i \in k}^{k}M_{i}^{2}}{N^{2}}.
%\label{eq:chance}
%\end{equation}
%
%Optimizing \ndmg~with respect to discriminability enables us to minimize the upper-bound on error for any general downstream inference task.
%Using discriminability for optimization also prevents over-fitting to covariate-specific signal (i.e. in contrast to optimizing the pipeline for sex classification).




\section{Discussion}


%The issues of reproducibility and batch effect spans essentially every discipline of science, although it has been particularly problematic in  omics~\cite{Leek2010-vs, Rosenfeld2010-nf, Chen2011, Nygaard2016-hw, Goh2017-hc} and more recently 
%The potential sources of variability  include
The goal of any scientific investigation is not to characterize the observed sample data’s variance, but rather, to make inferences about the general population on the basis of those data.  
Variability of sample demographics, data acquisition details (for example, number of repetitions for fMRI, number of directions for dMRI), analysis methods, measurement error, questionable research practices, or statistical errors can each contribute to limitations in generalizing to populations in psychology~\cite{Button2013} and neuroimaging~\cite{Costafreda2009}.
Our principles for pipeline development enabled a rigorous high-throughput analysis of multi-study, multi-site, and multi-connectome data to identify and quantify different sources of variability.

While perhaps seemingly at odds, the results from Figures~\ref{fig:siem} and~\ref{fig:batch} are complementary.  Specifically, Figure~\ref{fig:siem} demonstrates that essentially all connectomes share a particular property: stronger connections in one set of edges than another. On the other hand, Figure~\ref{fig:batch} demonstrates that although some sets of edges tend to be larger than others, the {magnitude} of the differences is highly variable both within and across studies. That the \emph{magnitude} of certain parameters can differ while the \emph{sign} of those parameters can be constant parallels recent suggestions from the statistics literature to move away from ``Type I'' and ``Type II'' errors, to Type M (magnitude) and Type  S (sign) errors~\cite{gelman14a}. Moreover, it suggests a strategy to understand and address batch effects: reporting the \emph{precision} for which effects are preserved or variable.  For example, in this study, when using the coarsest possible precision (larger versus smaller as in Figure~\ref{fig:siem}), no batch effects arise, whereas when using an extremely fine precision (the difference in magnitude as in Figure~\ref{fig:batch} ), batch effects are pervasive. The natural question then becomes: at which precision, for a given parameter and source of variability, do the studies still agree? Such analyses could then be incorporated into downstream analyses to preserve results across studies. 







%The \ndmg~pipeline is a reliable tool for structural and functional connectome estimation and analysis with  a low barrier to entry, and is capable of producing accurate brain-graphs across studies.
%
The design criteria for \ndmg~required certain trade-offs, including robustness under variability versus optimality under idealized data.  
% Optimizing \ndmg~for any individual dataset would make it sub-optimal for other datasets.  
Nonetheless, \ndmg, could be improved along several dimensions.
%Below we suggest several strategies that could  improve \ndmg~along various dimensions.
First, 
%several of the algorithm choices required trade-offs between accuracy and expediency, 
recent advances in registration~\cite{lddmm} and tractography ~\cite{probtrackx} could be incorporated.
When implementations for these algorithms achieve suitable expediency and robustness, it will be natural to assess them. 
Second, recently several more sophisticated batch effect strategies have been successfully employed in dMRI data~\cite{Fortin2017-dm}. Such strategies could possibly help here as well, especially if they are modified appropriately to work on binary graphs~\cite{Leek2007}.
%
Third, there is some evidence that machine learning approaches to mitigating batch effects can be effective as well, but so far only in fMRI data and only using four, rather than 18 studies~\cite{abraham2017deriving}.
Fourth, pre-processing strategies have been employed to improve multi-site reliability~\cite{mirzaalian2017harmonization}, so implementing methods such as these within \ndmg~could possibly mitigate some batch effects, at the risk of reducing accuracy and/or reliability~\cite{adhd}.
%First, several of the algorithm choices required trade-offs between accuracy and expediency, including registration~\cite{lddmm} and tractography.  When implementations for more accurate algorithms achieve suitable expediency, it will be natural to include them. 
%Second,  recently several more sophisticated batch effect strategies have been successfully employed in dMRI data~\cite{Fortin2017-dm}.  Such strategies could possibly help here as well, especially if they are modified appropriate to work on binary graphs~\cite{Leek2007,Chen2011} 
%Third, there is some evidence machine learning approaches to mitigating batch effects can be effective as well, but so far only in fMRI data and only using four, rather than 18 studies~\cite{abraham2017deriving}.
%Fourth, post-data collection stratification to harmonize study demographics has also been demonstrated to be effective to reduce batch effects of fMRI, although this study used only two studies with the same scanner~\cite{Noble2017}. 
%Pre-processing strategies have been employed to improve multi-site reliability~\cite{mirzaalian2017harmonization}, implementing  methods such as these within \ndmg~could possibly mitigate some batch effect, at the risk of reducing accuracy and/or reliability~\cite{adhd}.


%Other efforts have focused on multi-study data. Specifically, Abraham et al. \cite{abraham2017deriving}
%%Multi-site predictive tasks have been performed considering 
%used fMRI-derived connectomes from the ABIDE dataset, and demonstrate an impressive ability to minimize batch effects. Unfortunately,  most ABIDE studies lack dMRI data, so a similar strategy for \ndmgd~is not currently possible.  Similarly, concomitant with our manuscript is Noble et al. \cite{Noble2017}, who conducted a multi-scanner analysis with harmonized  fMRI acquisition on 12 individuals.  The compelling results suggest that pooling across studies with harmonized acquisition can potentially improve reliability.
%%and performing similar analyses upon a multi-dataset collection of dMRI-derived connectomes is an exciting avenue for future exploration.
%Additionally, a variety of studies propose methods for post-acquisition data harmonization using either minimally pre-processed or raw MRI data~\cite{mirzaalian2017harmonization,Fortin2017-dm,adhd} that could be explored within the context of the \ndmg~pipeline.





% \ndmg~has been optimized with respect to discriminability, yet  one can always further improve the pipeline via incorporating additional algorithms, datasets, or metrics.  For example, one could further optimize to reduce the batch effect.
%Alternately, one could incorporate probabilistic tractography to compare with deterministic approaches in a principled meganalysis using the open source data derivatives generated here.
%an exhaustive hyper-parameter sweep optimizing each parameter selection in \ndmg~has not yet been conducted.
%Though this has not occurred, an important contribution of \ndmg~is the illustration that highly sophisticated and computationally burdensome algorithms such as probabilistic tractography are not necessary to create reliable estimates of brain connectivity.
%Evaluating the quality of connectome estimation pipelines using probabilistic tractography with discriminability would enable a decisive answer to the question of when deterministic or probabilistic tractography is a more reliable when estimating connectivity, and by how much.




%Several previously proposed fMRI or dMRI pipelines utilize different algorithms which could also be incorporated, but have not been investigated here for various reasons.  CPAC~\cite{cpac}, PANDAS~\cite{Cui2013}, and CMTK~\cite{Daducci2012},   are flexible pipelines enabling users to select hyper-parameters for their dataset. This is a useful feature for many applications, but when the desire is to increase reliability, harmonization is key.
%%This freedom emphasizes the between-dataset differences in connectomes estimated with varying processing parameters, and cannot necessarily be directly compared.
% MRCAP~\cite{mrcap} and MIGRAINE~\cite{migraine} provide reference pipelines, but are difficult to deploy, and also lack vetting across studies. 
%%In the present study, we chose many pipelines for the evaluation while some existing pipelines were not included for such a purpose. 
%%Several analytic pipelines of resting-state fMRI that we did not evaluate above include
%REST~\cite{Song2011}, DPARSF~\cite{Yan2010}, DPABI~\cite{Yan2016}, GRETNA~\cite{Wang2015}, and GIFT~\cite{Calhoun2001-wc} lack command line interfaces and therefore are much more difficult to run at scale in a reliable fashion. 
%%limited to  are very popular with user-friendly graphic user interfaces (GUIs), however, it is not trivial for users to translate them into  computational platforms for  very large-scale neuroimaging data analysis. 
%Surface-based pipelines of rfMRI data such as connectome computation system (CCS)~\cite{Xu2015} and HCP (only volume-based part was included in the current evaluation) will be investigated in future work~\cite{Zuo2013}.


It may be that analysis methods on their own are insufficient to mitigate replicability issues, and that further improving data acquisition and/or data acquisition harmonization may be required. Indeed, a recent study by Noble et al.~\cite{Noble2017} found relatively few batch effects in fMRI data, although it employed only two datasets with enhanced and harmonized data acquisition protocols. 

%that post-data collection stratification to harmonize study demographics effectively to reduce batch effects of fMRI, although only in one much smaller mega-level analysis using  two studies with the same scanner.  


%However, while the algorithms that these pipelines leverage have become standard, the pipelines have not. Indeed, there is a distinct lack of reference pipelines in the field. This has resulted in each publication using  (sometimes subtly) different parameters, often without specifying  precise details and dependencies, making reproducibility difficult.  Moreover, the lack of reference pipelines also creates inefficiencies in the collective scientific process because pipelines have to be designed and tuned for each study, essentially.  


Because the methods developed herein are open source and easy to use, and the data are open access, this work enables further studies to assess measurement errors as well as variability of sample demographics and experimental protocols. For example, data could be sub-sampled to only include scans that pass stringent quality assurance standards, or have a sufficiently long duration to support discriminable connectomes~\cite{Airan17}.
% @EB: update citation.
 Alternately, this analysis could be repeated on data that is ``perfectly'' harmonized. In general, further work developing and applying experimental and theoretical tools to parse the relative impact of various sources of batch effects, as well as batch effect mitigation strategies, will be crucial for neuroimaging to achieve its greatest potential scientific and clinical value. 

%Perhaps even more problematic is that such pipelines cannot readily be used for meganalysis (an approach that pools data across datasets, centers, or studies) because most  are idiosyncratically designed for a particular study~\cite{Costafreda2009}. This stifles our ability to understand and quantify batch effects in neuroimaging, which are extremely problematic in -omics data~\cite{Leek2010-vs, Rosenfeld2010-nf, Nygaard2016-hw, Goh2017-hc}, though relatively understudied~\cite{Olivetti2012-vy, Fortin2016-yq, Fortin2017-dm}.



%The Human Connectome Project (HCP) has recently collected an extraordinary M3R dataset, and developed processing
%pipelines accordingly. It is our belief that \ndmg~is explicitly not in competition with the tools and resources
%produced by HCP. The HCP pipeline when run on the HCP data creates likely the most outstanding map of human brain
%connectivity to date, however, their pipeline relies on many additional parameters and files (such as scanner bias
%fields, and multi-shell acquisitions of dMRI data), making it unable to be deployed across the majority of existing
%dMRI studies. \ndmg~takes the approach of being a generally useful, reliable, and impactful tool, without requiring
%state-of-the-art acquisitions which are not commonly available outside of next-gen experimental paradigms. \ndmg~can be
%deployed on the HCP data, though it would not take advantage of the additional scans and parameters acquired. We
%believe that the HCP pipelines and \ndmg~compliment one another, and comparing the two more closely is an exciting
%avenue to be explored in future work.
% @rjv: I'm not sure we nd this anymore? Good to keep written when reviewers ask, though. -gk


% \clearpage

% \end{multicols}

\paragraph{Acknowledgements} 
{\small
The authors from JHU are grateful for the support  by the XDATA program of the Defense Advanced Research Projects Agency (DARPA) administered through Air
Force Research Laboratory contract FA8750-12-2-0303;  DARPA SIMPLEX
program through SPAWAR contract N66001-15-C-4041;  DARPA GRAPHS
contract N66001-14-1-4028; National Science Foundation grant 1649880, 
 and
the Kavli Foundation for their support. We are grateful to Eric Walker$^{1, 5}$ and Tanay Agarwal$^{1, 5, 14}$ who helped with preliminary QA figures for \ndmgf.
Dr. Xi-Nian Zuo received funding support in China from the National Basic Research (973) Program (2015CB351702), the National R{\&}D Infrastructure and Facility Development Program "Fundamental Science Data Sharing Platform" (DKA2017-12-02-21), the Natural Science Foundation of China (81471740, 81220108014) and Beijing Municipal Science and Tech Commission (Z161100002616023, Z161100000216152).
Dr. Calhoun received funding from the NIH (P20GM103472 and R01EB020407) and the NSF (grant 1539067). % @jv: post acceptance, also acknowledge yummy & lion
}

\paragraph{Author Information}

\vspace{10pt}
{\small
GK$^{1, 2, *}$, EWB$^{1, 3, 5, *}$, WG$^{4, *}$, VCh$^{1, 3}$, DM$^{5}$, SR$^{6}$, XZ$^{7,8,9,10}$, DSM$^{11}$, RCC$^{12, 13}$, CEP$^{3, 14}$, BC$^{16}$, RJ$^{6}$, VCa$^{15}$, BC$^{16}$, RB$^{5}$, MPM$^{9}$, JTV$^{1,3,5,9,17,\dagger}$: \\
${^*}$ these authors contributed equally to the preparation of this manuscript.\\
\noindent${^1}$ Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA.\\
\noindent${^2}$ Department of Biomedical Engineering, McGill University, Baltimore, MD, USA.\\
\noindent${^3}$ Center for Imaging Science, Johns Hopkins University, Baltimore, MD, USA.\\
\noindent${^4}$ Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA.\\
\noindent${^5}$ Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.\\
\noindent${^6}$ Department of Psychology, University of New Mexico, Albuquerque, NM, USA. \\
\noindent${^7}$ Department of Psychology, University of Chinese Academy of Sciences (CAS), Beijing, China. \\
\noindent${^8}$ CAS Key Laboratory of Behavioral Science, Beijing, China. \\
\noindent${^9}$ Research Center for Lifespan Development of Mind and Brain (CLIMB), CAS Institute of Psychology, Beijing, China.\\
\noindent$^{10}$ Magnetic Resonance Imaging Research Center (MRIRC), CAS Institute of Psychology, Beijing, China.\\
\noindent$^{11}$ Department of Human Cognitive and Brain Sciences, Max-Planck Institute, Munich, Germany. \\
\noindent$^{12}$ Child Mind Institute, New York, NY, USA.\\
\noindent$^{13}$ Dell Medical School, University of Texas at Austin, Austin, TX, USA. \\
\noindent$^{14}$ Department of Statistics, Johns Hopkins University, MD, USA. \\
\noindent$^{15}$ Department of Biomedical Engineering, University of New Mexico, Albuquerque, NM, USA. \\
\noindent$^{16}$ Department of Biostatistics, Johns Hopkins University, MD, USA. \\
\noindent$^{17}$ Institute for Computational Medicine, Johns Hopkins University, Baltimore, MD, USA.\\
\noindent$^\dagger$ is the corresponding author: $\langle$\url{jovo@jhu.edu}$\rangle$}.
%${^7}$ University of New Mexico, Albuquerque, NM, USA. \\
%}
%\end{spacing}

%\subsection*{Declarations}
%\paragraph{Competing Interests} The authors declare no competing interests in this manuscript.

\paragraph{CoRR Members}
{\small
Jeffrey~S.~Anderson, Pierre~Bellec, Rasmus~M.~Birn, Bharat~B.~Biswal, Janusch~Blautzik, John~C.S.~Breitner, Randy~L.~Buckner, F.~Xavier~Castellanos, Antao~Chen, Bing~Chen, Jiangtao~Chen, Xu~Chen, Stanley~J.~Colcombe, William~Courtney, Adriana~Di~Martino, Hao-Ming~Dong, Xiaolan~Fu, Qiyong~Gong, Krzysztof~J.~Gorgolewski, Ying~Han, Ye~He, Yong~He, Erica~Ho, Avram~Holmes, Xiao-Hui~Hou, Jeremy~Huckins, Tianzi~Jiang, Yi~Jiang, William~Kelley, Clare~Kelly, Margaret~King, Stephen~M.~LaConte, Janet~E.~Lainhart, Xu~Lei, Hui-Jie~Li, Kaiming~Li, Kuncheng~Li, Qixiang~Lin, Dongqiang~Liu, Jia~Liu, Xun~Liu, Guangming~Lu, Jie~Lu, Beatriz~Luna, Jing~Luo, Daniel~Lurie, Ying~Mao, Andrew~R.~Mayer, Thomas~Meindl, Mary~E.~Meyerand, Weizhi~Nan, Jared~A.~Nielsen, David~O’Connor, David~Paulsen, Vivek~Prabhakaran, Zhigang~Qi, Jiang~Qiu, Chunhong~Shao, Zarrar~Shehzad, Weijun~Tang, Arno~Villringer, Huiling~Wang, Kai~Wang, Dongtao~Wei, Gao-Xia~Wei, Xu-Chu~Weng, Xuehai~Wu, Ting~Xu, Ning~Yang, Zhi~Yang, Yu-Feng~Zang, Lei~Zhang, Qinglin~Zhang, Zhe~Zhang, Zhiqiang~Zhang, Ke~Zhao, Zonglei~Zhen, Yuan~Zhou, Xing-Ting Zhu.
}

\vspace{-10pt}


\bibliographystyle{unsrtnat}
\begin{spacing}{0.3}
{\footnotesize  \bibliography{ndmg}}
\end{spacing}

\clearpage
\appendix

\renewcommand\thesection{Appendix~\Alph{section}}
\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0}

%%%%%%%
%\input{figure_end2end.tex}
%%%%%%%


\subsection{Group-Level Multi-Scale Analysis}
\label{app:multi}

Figure~\ref{fig:multiscale} top panel shows the group-level summary statistics of diffusion connectomes belonging to same dataset over 13 parcellations ranging from 48 nodes up to 500 nodes; for clarity, an additional 11 parcellations with up to over 70,000 nodes are not shown here. The bottom panel shows the group-level summary statistics of functional connectomes belonging to the same dataset over 5 parcellations ranging from 52 to 200 nodes. 
For each parcellation, vertex statistics are normalized by dividing them into number of vertices in the parcellation, and then smoothed via kernel-density estimation to enable comparison across scales. The kernel-width was computed using Scott's Rule, the default mode for Scipy (\url{https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.stats.gaussian_kde.html}).
For most of the statistics, the ``shape'' of the distributions  are relatively similar across scales, though their actual magnitudes can vary somewhat dramatically.
%In particular, in Figure~\ref{fig:multiscale}, graphs from the the downsampled block-atlases (DS) appear to be scaled versions of one another, as may be expected because they are related to one-another by a region-growing function~\cite{glocal}.

%%%%%%%
\input{figure_multiscale.tex}
%%%%%%%

%\clearpage
\subsection{Multi-Study Analysis}

Figure~\ref{fig:multisite} top panel shows a variety of uni- and multi-variate statistics of the average diffusion connectome from each of the studies enumerated in Table~\ref{tab:data} with diffusion data using the Desikan parcellation. The bottom panel shows the same statistics computed on the average functional connectome from each of the studies enumerated in Table~\ref{tab:data} with functional data using the Desikan parcellation. In both the diffusion and functional connectomes, each dataset largely appears to have similar trends across each of the statistics shown.

%%%%%%%
\input{figure_multisite.tex}
%%%%%%%


\section{Availability Statements}

\subsection{Code Availability}

All of our code is available from our website, \url{http://m2g.io/},  and has been deposited into our public github repository, \url{https://github.com/neurodata/ndmg}, and published with a DOI, \url{https://doi.org/10.5281/zenodo.1161284}, under the Apache License 2.0. 

\subsection{Data Availability}

The data derivatives that support the findings of this study are available from our website, \url{http://m2g.io/},  under a (ODC-By) v1.0 license.


\end{document}
